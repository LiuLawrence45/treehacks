{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man holding a cell phone', 'confidence': 0.7995043396949768, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man holding a cell phone', 'confidence': 0.8132568597793579, 'boundingBox': {'x': 90, 'y': 0, 'w': 1772, 'h': 1052}}, {'text': 'a close up of a phone', 'confidence': 0.8215231895446777, 'boundingBox': {'x': 846, 'y': 747, 'w': 487, 'h': 320}}, {'text': 'a green sign with white text', 'confidence': 0.6918546557426453, 'boundingBox': {'x': 594, 'y': 373, 'w': 61, 'h': 57}}, {'text': "a person's back with a white jacket", 'confidence': 0.6698318719863892, 'boundingBox': {'x': 1610, 'y': 481, 'w': 301, 'h': 530}}, {'text': 'a close up of a black box', 'confidence': 0.6800532937049866, 'boundingBox': {'x': 1523, 'y': 406, 'w': 175, 'h': 130}}, {'text': 'a green tube in a circle', 'confidence': 0.6207846999168396, 'boundingBox': {'x': 0, 'y': 723, 'w': 73, 'h': 64}}, {'text': 'a man taking a selfie', 'confidence': 0.8657627105712891, 'boundingBox': {'x': 730, 'y': 0, 'w': 626, 'h': 657}}, {'text': 'a red circle with white text', 'confidence': 0.6734902858734131, 'boundingBox': {'x': 1014, 'y': 858, 'w': 70, 'h': 55}}, {'text': 'a balloon from the ceiling', 'confidence': 0.7555323839187622, 'boundingBox': {'x': 397, 'y': 0, 'w': 229, 'h': 694}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 44, 'y': 0, 'w': 1869, 'h': 1077}, 'confidence': 0.9618109464645386}, {'boundingBox': {'x': 1618, 'y': 494, 'w': 299, 'h': 505}, 'confidence': 0.8894752264022827}, {'boundingBox': {'x': 0, 'y': 656, 'w': 51, 'h': 230}, 'confidence': 0.34584540128707886}, {'boundingBox': {'x': 336, 'y': 672, 'w': 177, 'h': 187}, 'confidence': 0.17467723786830902}, {'boundingBox': {'x': 1685, 'y': 674, 'w': 92, 'h': 92}, 'confidence': 0.025248246267437935}, {'boundingBox': {'x': 1661, 'y': 639, 'w': 142, 'h': 163}, 'confidence': 0.0045643094927072525}, {'boundingBox': {'x': 0, 'y': 623, 'w': 71, 'h': 419}, 'confidence': 0.003350546583533287}, {'boundingBox': {'x': 748, 'y': 290, 'w': 438, 'h': 536}, 'confidence': 0.002707734005525708}, {'boundingBox': {'x': 0, 'y': 746, 'w': 43, 'h': 106}, 'confidence': 0.0015758045483380556}, {'boundingBox': {'x': 992, 'y': 801, 'w': 80, 'h': 45}, 'confidence': 0.0011246935464441776}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man holding a device', 'confidence': 0.776459276676178, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man looking at a cell phone', 'confidence': 0.7963154911994934, 'boundingBox': {'x': 87, 'y': 0, 'w': 1776, 'h': 1049}}, {'text': 'a close up of a computer screen', 'confidence': 0.7167671322822571, 'boundingBox': {'x': 941, 'y': 930, 'w': 471, 'h': 142}}, {'text': "a person's back with a white jacket", 'confidence': 0.6539631485939026, 'boundingBox': {'x': 1613, 'y': 483, 'w': 300, 'h': 508}}, {'text': 'a green sign on a ceiling', 'confidence': 0.7338669896125793, 'boundingBox': {'x': 595, 'y': 373, 'w': 61, 'h': 56}}, {'text': 'a person holding a phone', 'confidence': 0.6836614608764648, 'boundingBox': {'x': 815, 'y': 614, 'w': 333, 'h': 449}}, {'text': 'a close-up of a phone', 'confidence': 0.7756712436676025, 'boundingBox': {'x': 1523, 'y': 405, 'w': 175, 'h': 131}}, {'text': 'a green object in the air', 'confidence': 0.6168191432952881, 'boundingBox': {'x': 0, 'y': 722, 'w': 73, 'h': 65}}, {'text': "a close up of a man's face", 'confidence': 0.8623878359794617, 'boundingBox': {'x': 776, 'y': 2, 'w': 537, 'h': 636}}, {'text': 'a close up of a nose', 'confidence': 0.8503233790397644, 'boundingBox': {'x': 968, 'y': 329, 'w': 143, 'h': 190}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 40, 'y': 0, 'w': 1868, 'h': 1077}, 'confidence': 0.9599985480308533}, {'boundingBox': {'x': 1611, 'y': 496, 'w': 306, 'h': 502}, 'confidence': 0.8963714241981506}, {'boundingBox': {'x': 0, 'y': 658, 'w': 51, 'h': 229}, 'confidence': 0.3886314332485199}, {'boundingBox': {'x': 332, 'y': 673, 'w': 183, 'h': 189}, 'confidence': 0.2620810568332672}, {'boundingBox': {'x': 1671, 'y': 682, 'w': 101, 'h': 89}, 'confidence': 0.019061237573623657}, {'boundingBox': {'x': 1662, 'y': 635, 'w': 170, 'h': 197}, 'confidence': 0.009175695478916168}, {'boundingBox': {'x': 0, 'y': 655, 'w': 70, 'h': 422}, 'confidence': 0.0032672302331775427}, {'boundingBox': {'x': 745, 'y': 293, 'w': 444, 'h': 531}, 'confidence': 0.0026213894598186016}, {'boundingBox': {'x': 0, 'y': 746, 'w': 44, 'h': 106}, 'confidence': 0.001782259321771562}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man looking away from camera', 'confidence': 0.6406136751174927, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man looking at something', 'confidence': 0.655084490776062, 'boundingBox': {'x': 89, 'y': 0, 'w': 1765, 'h': 1048}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8838284015655518, 'boundingBox': {'x': 795, 'y': 542, 'w': 333, 'h': 519}}, {'text': 'a person in a white jacket', 'confidence': 0.6912941932678223, 'boundingBox': {'x': 1607, 'y': 482, 'w': 304, 'h': 524}}, {'text': 'a close up of a phone', 'confidence': 0.7510979771614075, 'boundingBox': {'x': 1522, 'y': 405, 'w': 176, 'h': 131}}, {'text': 'a green sign with white text', 'confidence': 0.7327564358711243, 'boundingBox': {'x': 596, 'y': 373, 'w': 58, 'h': 56}}, {'text': 'a close up of a green tube', 'confidence': 0.730355441570282, 'boundingBox': {'x': 0, 'y': 723, 'w': 74, 'h': 64}}, {'text': 'a man looking up to the side', 'confidence': 0.6813565492630005, 'boundingBox': {'x': 620, 'y': 0, 'w': 643, 'h': 642}}, {'text': "close up of a person's ear", 'confidence': 0.8484674692153931, 'boundingBox': {'x': 1063, 'y': 230, 'w': 142, 'h': 199}}, {'text': "a close up of a person's eye", 'confidence': 0.8104986548423767, 'boundingBox': {'x': 796, 'y': 214, 'w': 85, 'h': 67}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 62, 'y': 0, 'w': 1838, 'h': 1077}, 'confidence': 0.9551975131034851}, {'boundingBox': {'x': 1605, 'y': 496, 'w': 312, 'h': 503}, 'confidence': 0.8935884237289429}, {'boundingBox': {'x': 341, 'y': 668, 'w': 185, 'h': 201}, 'confidence': 0.634736180305481}, {'boundingBox': {'x': 0, 'y': 654, 'w': 52, 'h': 238}, 'confidence': 0.3373815417289734}, {'boundingBox': {'x': 1678, 'y': 683, 'w': 96, 'h': 85}, 'confidence': 0.01878121867775917}, {'boundingBox': {'x': 1658, 'y': 626, 'w': 152, 'h': 173}, 'confidence': 0.0067198872566223145}, {'boundingBox': {'x': 744, 'y': 287, 'w': 445, 'h': 536}, 'confidence': 0.002627927577123046}, {'boundingBox': {'x': 0, 'y': 680, 'w': 73, 'h': 382}, 'confidence': 0.0014285986544564366}, {'boundingBox': {'x': 0, 'y': 746, 'w': 44, 'h': 106}, 'confidence': 0.0012526820646598935}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man taking a selfie', 'confidence': 0.8552293181419373, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man taking a selfie', 'confidence': 0.8463187217712402, 'boundingBox': {'x': 87, 'y': 0, 'w': 1755, 'h': 1048}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8837333917617798, 'boundingBox': {'x': 806, 'y': 598, 'w': 318, 'h': 463}}, {'text': 'a green sign with white text', 'confidence': 0.6843407154083252, 'boundingBox': {'x': 596, 'y': 373, 'w': 58, 'h': 56}}, {'text': 'a close up of a black box', 'confidence': 0.6880884766578674, 'boundingBox': {'x': 1523, 'y': 406, 'w': 175, 'h': 130}}, {'text': 'a person in a white jacket', 'confidence': 0.6901400685310364, 'boundingBox': {'x': 1604, 'y': 482, 'w': 306, 'h': 543}}, {'text': 'a green tube in a circle', 'confidence': 0.6189500689506531, 'boundingBox': {'x': 0, 'y': 723, 'w': 74, 'h': 64}}, {'text': "a close up of a man's face", 'confidence': 0.8659313321113586, 'boundingBox': {'x': 683, 'y': 0, 'w': 557, 'h': 644}}, {'text': "a close up of a person's nose", 'confidence': 0.9022977352142334, 'boundingBox': {'x': 910, 'y': 330, 'w': 141, 'h': 191}}, {'text': "a close up of a person's face", 'confidence': 0.874886155128479, 'boundingBox': {'x': 497, 'y': 6, 'w': 914, 'h': 376}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 57, 'y': 0, 'w': 1839, 'h': 1077}, 'confidence': 0.9570329189300537}, {'boundingBox': {'x': 1606, 'y': 497, 'w': 311, 'h': 505}, 'confidence': 0.9021823406219482}, {'boundingBox': {'x': 367, 'y': 673, 'w': 159, 'h': 181}, 'confidence': 0.5947195887565613}, {'boundingBox': {'x': 0, 'y': 656, 'w': 51, 'h': 227}, 'confidence': 0.34396231174468994}, {'boundingBox': {'x': 1677, 'y': 679, 'w': 100, 'h': 96}, 'confidence': 0.03106176108121872}, {'boundingBox': {'x': 745, 'y': 289, 'w': 442, 'h': 533}, 'confidence': 0.0024449178017675877}, {'boundingBox': {'x': 0, 'y': 652, 'w': 70, 'h': 424}, 'confidence': 0.002369987778365612}, {'boundingBox': {'x': 0, 'y': 461, 'w': 76, 'h': 453}, 'confidence': 0.0011009147856384516}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man taking a selfie', 'confidence': 0.8863154649734497, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man taking a selfie', 'confidence': 0.865574836730957, 'boundingBox': {'x': 91, 'y': 0, 'w': 1656, 'h': 1048}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8935361504554749, 'boundingBox': {'x': 779, 'y': 570, 'w': 292, 'h': 492}}, {'text': 'a close up of a phone', 'confidence': 0.7365190982818604, 'boundingBox': {'x': 1523, 'y': 407, 'w': 173, 'h': 129}}, {'text': 'a man taking a selfie', 'confidence': 0.8572546243667603, 'boundingBox': {'x': 626, 'y': 0, 'w': 569, 'h': 635}}, {'text': 'a person sitting in a chair', 'confidence': 0.6866803765296936, 'boundingBox': {'x': 1570, 'y': 485, 'w': 338, 'h': 572}}, {'text': 'a close up of a green tube', 'confidence': 0.7290397882461548, 'boundingBox': {'x': 0, 'y': 723, 'w': 73, 'h': 64}}, {'text': 'a green sign with white text', 'confidence': 0.6934932470321655, 'boundingBox': {'x': 594, 'y': 376, 'w': 60, 'h': 57}}, {'text': "a close up of a person's face", 'confidence': 0.876509428024292, 'boundingBox': {'x': 279, 'y': 3, 'w': 1183, 'h': 390}}, {'text': "a close up of a person's nose", 'confidence': 0.916027307510376, 'boundingBox': {'x': 875, 'y': 335, 'w': 144, 'h': 147}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 72, 'y': 0, 'w': 1710, 'h': 1077}, 'confidence': 0.958871603012085}, {'boundingBox': {'x': 1577, 'y': 497, 'w': 340, 'h': 508}, 'confidence': 0.9196845293045044}, {'boundingBox': {'x': 0, 'y': 658, 'w': 52, 'h': 233}, 'confidence': 0.3340963125228882}, {'boundingBox': {'x': 367, 'y': 672, 'w': 159, 'h': 183}, 'confidence': 0.3048449754714966}, {'boundingBox': {'x': 1677, 'y': 484, 'w': 240, 'h': 302}, 'confidence': 0.01647382415831089}, {'boundingBox': {'x': 980, 'y': 948, 'w': 19, 'h': 47}, 'confidence': 0.0034346014726907015}, {'boundingBox': {'x': 0, 'y': 661, 'w': 71, 'h': 416}, 'confidence': 0.002447995822876692}, {'boundingBox': {'x': 733, 'y': 285, 'w': 472, 'h': 544}, 'confidence': 0.0022967392578721046}, {'boundingBox': {'x': 858, 'y': 994, 'w': 25, 'h': 44}, 'confidence': 0.0017032008618116379}, {'boundingBox': {'x': 0, 'y': 747, 'w': 44, 'h': 105}, 'confidence': 0.0013551913434639573}, {'boundingBox': {'x': 1683, 'y': 588, 'w': 147, 'h': 233}, 'confidence': 0.0011710471007972956}]}}
