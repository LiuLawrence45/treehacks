{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a person holding a red package', 'confidence': 0.773316502571106, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a package of crackers', 'confidence': 0.8495794534683228, 'boundingBox': {'x': 348, 'y': 0, 'w': 1192, 'h': 524}}, {'text': 'a person with a red bag of crackers covering their eyes', 'confidence': 0.7451126575469971, 'boundingBox': {'x': 0, 'y': 226, 'w': 1892, 'h': 825}}, {'text': 'a close up of a logo', 'confidence': 0.8023027777671814, 'boundingBox': {'x': 578, 'y': 96, 'w': 276, 'h': 257}}, {'text': 'a person wearing a lanyard with a white and green design on it', 'confidence': 0.7116633057594299, 'boundingBox': {'x': 759, 'y': 582, 'w': 345, 'h': 486}}, {'text': 'a person wearing a black hoodie and a lanyard', 'confidence': 0.7486637830734253, 'boundingBox': {'x': 417, 'y': 468, 'w': 1186, 'h': 596}}, {'text': 'a close up of a hand', 'confidence': 0.8150340914726257, 'boundingBox': {'x': 0, 'y': 282, 'w': 469, 'h': 774}}, {'text': 'a close up of a fried food', 'confidence': 0.717449963092804, 'boundingBox': {'x': 872, 'y': 94, 'w': 288, 'h': 248}}, {'text': 'a close up of a hand', 'confidence': 0.8133297562599182, 'boundingBox': {'x': 1439, 'y': 228, 'w': 468, 'h': 826}}, {'text': 'a close up of a white object', 'confidence': 0.6971952319145203, 'boundingBox': {'x': 779, 'y': 610, 'w': 123, 'h': 458}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 0, 'y': 0, 'w': 1917, 'h': 1077}, 'confidence': 0.9559314846992493}, {'boundingBox': {'x': 717, 'y': 0, 'w': 451, 'h': 56}, 'confidence': 0.0038422553334385157}, {'boundingBox': {'x': 720, 'y': 283, 'w': 484, 'h': 557}, 'confidence': 0.0035460253711789846}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a person holding a red package of crackers', 'confidence': 0.8011763691902161, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a package of crackers', 'confidence': 0.8737976551055908, 'boundingBox': {'x': 353, 'y': 0, 'w': 1141, 'h': 576}}, {'text': 'a person with a bag of crackers', 'confidence': 0.8585196137428284, 'boundingBox': {'x': 0, 'y': 217, 'w': 1891, 'h': 831}}, {'text': 'a logo on a red background', 'confidence': 0.7175955772399902, 'boundingBox': {'x': 589, 'y': 116, 'w': 267, 'h': 252}}, {'text': 'a close up of food', 'confidence': 0.746209442615509, 'boundingBox': {'x': 872, 'y': 121, 'w': 277, 'h': 233}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8557431101799011, 'boundingBox': {'x': 784, 'y': 578, 'w': 335, 'h': 489}}, {'text': 'a close up of a hand', 'confidence': 0.8644060492515564, 'boundingBox': {'x': 0, 'y': 274, 'w': 478, 'h': 774}}, {'text': 'a person wearing a lanyard', 'confidence': 0.7620254158973694, 'boundingBox': {'x': 434, 'y': 481, 'w': 1170, 'h': 582}}, {'text': "close up of a person's hand", 'confidence': 0.8085773587226868, 'boundingBox': {'x': 1427, 'y': 218, 'w': 484, 'h': 843}}, {'text': "close up of a person's mouth", 'confidence': 0.8422540426254272, 'boundingBox': {'x': 883, 'y': 515, 'w': 192, 'h': 78}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 0, 'y': 0, 'w': 1914, 'h': 1077}, 'confidence': 0.9431061744689941}, {'boundingBox': {'x': 1014, 'y': 942, 'w': 22, 'h': 45}, 'confidence': 0.0053960541263222694}, {'boundingBox': {'x': 720, 'y': 288, 'w': 477, 'h': 549}, 'confidence': 0.0033494699746370316}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a person holding a red package of crackers', 'confidence': 0.83240807056427, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a red package of crackers', 'confidence': 0.8000794053077698, 'boundingBox': {'x': 366, 'y': 3, 'w': 1380, 'h': 747}}, {'text': 'a close up of a logo', 'confidence': 0.798523485660553, 'boundingBox': {'x': 634, 'y': 190, 'w': 319, 'h': 302}}, {'text': 'a close up of food', 'confidence': 0.7644261717796326, 'boundingBox': {'x': 975, 'y': 186, 'w': 340, 'h': 284}}, {'text': 'a person holding a red package of crackers', 'confidence': 0.7977483868598938, 'boundingBox': {'x': 0, 'y': 214, 'w': 1889, 'h': 828}}, {'text': 'a close up of a hand', 'confidence': 0.8837934136390686, 'boundingBox': {'x': 0, 'y': 388, 'w': 530, 'h': 669}}, {'text': 'a close up of a black object', 'confidence': 0.6577259302139282, 'boundingBox': {'x': 785, 'y': 0, 'w': 621, 'h': 134}}, {'text': 'a blurry image of a green balloon', 'confidence': 0.7364753484725952, 'boundingBox': {'x': 510, 'y': 0, 'w': 131, 'h': 138}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8109840750694275, 'boundingBox': {'x': 848, 'y': 677, 'w': 305, 'h': 392}}, {'text': "a blurry image of a person's head", 'confidence': 0.8081328272819519, 'boundingBox': {'x': 566, 'y': 2, 'w': 989, 'h': 165}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 0, 'y': 1, 'w': 1917, 'h': 1076}, 'confidence': 0.9505640864372253}, {'boundingBox': {'x': 730, 'y': 283, 'w': 467, 'h': 549}, 'confidence': 0.0034410629887133837}, {'boundingBox': {'x': 1086, 'y': 946, 'w': 21, 'h': 46}, 'confidence': 0.001847569947130978}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a person holding a red package of crackers', 'confidence': 0.8348451852798462, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a package of crackers', 'confidence': 0.8565526008605957, 'boundingBox': {'x': 396, 'y': 0, 'w': 1422, 'h': 742}}, {'text': 'a close up of a logo', 'confidence': 0.8140801787376404, 'boundingBox': {'x': 672, 'y': 145, 'w': 328, 'h': 301}}, {'text': 'a close up of a hand', 'confidence': 0.8679405450820923, 'boundingBox': {'x': 0, 'y': 337, 'w': 545, 'h': 719}}, {'text': 'a blurry image of food', 'confidence': 0.7476548552513123, 'boundingBox': {'x': 1033, 'y': 133, 'w': 517, 'h': 297}}, {'text': 'a person holding a bag of crackers', 'confidence': 0.8400309085845947, 'boundingBox': {'x': 0, 'y': 294, 'w': 1891, 'h': 751}}, {'text': 'a person wearing a lanyard with a black shirt', 'confidence': 0.7225717306137085, 'boundingBox': {'x': 885, 'y': 655, 'w': 307, 'h': 416}}, {'text': 'a blurry image of a green object', 'confidence': 0.7183944582939148, 'boundingBox': {'x': 521, 'y': 2, 'w': 114, 'h': 96}}, {'text': "a close up of a person's body", 'confidence': 0.7363696694374084, 'boundingBox': {'x': 738, 'y': 1, 'w': 638, 'h': 97}}, {'text': 'a person wearing a lanyard with a black shirt and a black shirt', 'confidence': 0.7210708260536194, 'boundingBox': {'x': 407, 'y': 569, 'w': 1218, 'h': 481}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 2, 'y': 1, 'w': 1717, 'h': 1076}, 'confidence': 0.6858162879943848}, {'boundingBox': {'x': 641, 'y': 292, 'w': 459, 'h': 536}, 'confidence': 0.0013452765997499228}, {'boundingBox': {'x': 1553, 'y': 16, 'w': 364, 'h': 1061}, 'confidence': 0.001211123657412827}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man in a black hoodie', 'confidence': 0.7359181046485901, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man in a black hoodie', 'confidence': 0.7090870141983032, 'boundingBox': {'x': 291, 'y': 0, 'w': 1489, 'h': 1051}}, {'text': 'a green sign with letters on it', 'confidence': 0.7032469511032104, 'boundingBox': {'x': 595, 'y': 373, 'w': 60, 'h': 56}}, {'text': 'a close up of a phone', 'confidence': 0.7492842078208923, 'boundingBox': {'x': 1522, 'y': 406, 'w': 175, 'h': 129}}, {'text': 'a person holding a fist', 'confidence': 0.5967234373092651, 'boundingBox': {'x': 578, 'y': 506, 'w': 907, 'h': 551}}, {'text': 'a person in a white jacket', 'confidence': 0.6705635190010071, 'boundingBox': {'x': 1648, 'y': 486, 'w': 263, 'h': 555}}, {'text': 'a green object in a hand', 'confidence': 0.6158885955810547, 'boundingBox': {'x': 0, 'y': 722, 'w': 73, 'h': 64}}, {'text': "a close up of a man's face", 'confidence': 0.8234245181083679, 'boundingBox': {'x': 736, 'y': 50, 'w': 526, 'h': 603}}, {'text': 'a string from the ceiling', 'confidence': 0.6968485116958618, 'boundingBox': {'x': 395, 'y': 0, 'w': 227, 'h': 761}}, {'text': "a person's head with a white shirt", 'confidence': 0.6761163473129272, 'boundingBox': {'x': 1722, 'y': 498, 'w': 194, 'h': 199}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 289, 'y': 1, 'w': 1514, 'h': 1076}, 'confidence': 0.9341173768043518}, {'boundingBox': {'x': 1648, 'y': 500, 'w': 269, 'h': 499}, 'confidence': 0.8894972801208496}, {'boundingBox': {'x': 339, 'y': 690, 'w': 203, 'h': 187}, 'confidence': 0.6450434327125549}, {'boundingBox': {'x': 0, 'y': 654, 'w': 51, 'h': 237}, 'confidence': 0.33010077476501465}, {'boundingBox': {'x': 1668, 'y': 674, 'w': 107, 'h': 100}, 'confidence': 0.017582176253199577}, {'boundingBox': {'x': 1773, 'y': 671, 'w': 144, 'h': 405}, 'confidence': 0.005375186447054148}, {'boundingBox': {'x': 257, 'y': 688, 'w': 286, 'h': 342}, 'confidence': 0.003569664666429162}, {'boundingBox': {'x': 0, 'y': 659, 'w': 73, 'h': 418}, 'confidence': 0.0032292522955685854}, {'boundingBox': {'x': 1664, 'y': 634, 'w': 156, 'h': 181}, 'confidence': 0.002785927150398493}, {'boundingBox': {'x': 791, 'y': 276, 'w': 543, 'h': 559}, 'confidence': 0.002684513106942177}, {'boundingBox': {'x': 0, 'y': 747, 'w': 43, 'h': 105}, 'confidence': 0.0014544174773618579}]}}
