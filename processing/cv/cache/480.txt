{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle and a laptop', 'confidence': 0.8548150062561035, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a hand holding a plastic bottle', 'confidence': 0.7777625322341919, 'boundingBox': {'x': 915, 'y': 328, 'w': 160, 'h': 379}}, {'text': 'a woman holding a water bottle and a laptop', 'confidence': 0.836484432220459, 'boundingBox': {'x': 432, 'y': 0, 'w': 740, 'h': 1046}}, {'text': 'a person in a black jacket', 'confidence': 0.7023891806602478, 'boundingBox': {'x': 1514, 'y': 0, 'w': 395, 'h': 1064}}, {'text': 'a woman holding a water bottle and a laptop', 'confidence': 0.8834001421928406, 'boundingBox': {'x': 0, 'y': 0, 'w': 1889, 'h': 1044}}, {'text': 'a woman taking a selfie', 'confidence': 0.8447736501693726, 'boundingBox': {'x': 180, 'y': 9, 'w': 1539, 'h': 373}}, {'text': 'a woman with long hair', 'confidence': 0.692929744720459, 'boundingBox': {'x': 680, 'y': 6, 'w': 381, 'h': 316}}, {'text': 'a white piece of paper', 'confidence': 0.7951313853263855, 'boundingBox': {'x': 44, 'y': 480, 'w': 59, 'h': 60}}, {'text': 'a person holding a laptop and a bottle of water', 'confidence': 0.8601049780845642, 'boundingBox': {'x': 529, 'y': 224, 'w': 492, 'h': 653}}, {'text': 'a close up of a white object', 'confidence': 0.6612949371337891, 'boundingBox': {'x': 1840, 'y': 513, 'w': 79, 'h': 555}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 461, 'y': 1, 'w': 732, 'h': 1076}, 'confidence': 0.9656546115875244}, {'boundingBox': {'x': 1526, 'y': 1, 'w': 391, 'h': 1076}, 'confidence': 0.9543429613113403}, {'boundingBox': {'x': 1197, 'y': 437, 'w': 202, 'h': 328}, 'confidence': 0.878454327583313}, {'boundingBox': {'x': 1009, 'y': 366, 'w': 707, 'h': 434}, 'confidence': 0.0018112895777449012}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a bottle of water and a laptop', 'confidence': 0.856911301612854, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a woman holding a bottle of water and a laptop', 'confidence': 0.8668972253799438, 'boundingBox': {'x': 435, 'y': 0, 'w': 735, 'h': 1047}}, {'text': 'a close up of a bottle', 'confidence': 0.7609771490097046, 'boundingBox': {'x': 952, 'y': 313, 'w': 131, 'h': 396}}, {'text': 'a person in a hoodie', 'confidence': 0.7758920192718506, 'boundingBox': {'x': 1477, 'y': 0, 'w': 422, 'h': 1051}}, {'text': 'a woman holding a bottle of water and a laptop', 'confidence': 0.8594884276390076, 'boundingBox': {'x': 0, 'y': 0, 'w': 1894, 'h': 1044}}, {'text': 'a woman taking a selfie', 'confidence': 0.8472112417221069, 'boundingBox': {'x': 185, 'y': 9, 'w': 1513, 'h': 384}}, {'text': "a blurry image of a person's leg", 'confidence': 0.8118166327476501, 'boundingBox': {'x': 1420, 'y': 421, 'w': 110, 'h': 345}}, {'text': 'a close up of a band', 'confidence': 0.7387437224388123, 'boundingBox': {'x': 1801, 'y': 506, 'w': 115, 'h': 556}}, {'text': 'a white piece of paper', 'confidence': 0.8226979970932007, 'boundingBox': {'x': 44, 'y': 480, 'w': 59, 'h': 59}}, {'text': 'a woman with long hair', 'confidence': 0.6961781978607178, 'boundingBox': {'x': 672, 'y': 7, 'w': 391, 'h': 343}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 464, 'y': 1, 'w': 730, 'h': 1076}, 'confidence': 0.9647641777992249}, {'boundingBox': {'x': 1498, 'y': 1, 'w': 418, 'h': 1076}, 'confidence': 0.9529847502708435}, {'boundingBox': {'x': 1427, 'y': 428, 'w': 100, 'h': 334}, 'confidence': 0.8657267093658447}, {'boundingBox': {'x': 1252, 'y': 512, 'w': 96, 'h': 249}, 'confidence': 0.853528618812561}, {'boundingBox': {'x': 1175, 'y': 581, 'w': 87, 'h': 179}, 'confidence': 0.0028064532671123743}, {'boundingBox': {'x': 1582, 'y': 585, 'w': 24, 'h': 28}, 'confidence': 0.0020350879058241844}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle and a phone', 'confidence': 0.7598146200180054, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a hand holding a plastic bottle', 'confidence': 0.7959726452827454, 'boundingBox': {'x': 927, 'y': 353, 'w': 170, 'h': 376}}, {'text': 'a woman holding a water bottle and a laptop', 'confidence': 0.8591842651367188, 'boundingBox': {'x': 446, 'y': 0, 'w': 739, 'h': 1053}}, {'text': 'a hand holding a phone', 'confidence': 0.8095787763595581, 'boundingBox': {'x': 1180, 'y': 142, 'w': 307, 'h': 359}}, {'text': 'a man taking a selfie', 'confidence': 0.8568431735038757, 'boundingBox': {'x': 1175, 'y': 17, 'w': 724, 'h': 1031}}, {'text': 'a woman holding a bottle of water and a laptop', 'confidence': 0.7852752804756165, 'boundingBox': {'x': 224, 'y': 0, 'w': 1642, 'h': 1047}}, {'text': 'a white piece of paper', 'confidence': 0.7991282939910889, 'boundingBox': {'x': 45, 'y': 480, 'w': 57, 'h': 58}}, {'text': 'a pink book with black text', 'confidence': 0.6935668587684631, 'boundingBox': {'x': 400, 'y': 632, 'w': 113, 'h': 133}}, {'text': 'a man wearing a hoodie', 'confidence': 0.7707274556159973, 'boundingBox': {'x': 1533, 'y': 37, 'w': 378, 'h': 603}}, {'text': 'a person holding a bottle of water', 'confidence': 0.8734287023544312, 'boundingBox': {'x': 553, 'y': 250, 'w': 516, 'h': 682}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 455, 'y': 1, 'w': 743, 'h': 1076}, 'confidence': 0.9654110670089722}, {'boundingBox': {'x': 1190, 'y': 40, 'w': 727, 'h': 1037}, 'confidence': 0.9287968277931213}, {'boundingBox': {'x': 1315, 'y': 691, 'w': 30, 'h': 71}, 'confidence': 0.0019699535332620144}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle and a phone', 'confidence': 0.7670280933380127, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a woman holding a phone and a water bottle', 'confidence': 0.8173115849494934, 'boundingBox': {'x': 458, 'y': 1, 'w': 702, 'h': 1067}}, {'text': 'a hand holding a plastic bottle', 'confidence': 0.7815308570861816, 'boundingBox': {'x': 911, 'y': 438, 'w': 154, 'h': 302}}, {'text': 'a person holding a phone', 'confidence': 0.8101294040679932, 'boundingBox': {'x': 957, 'y': 307, 'w': 342, 'h': 242}}, {'text': 'a man and woman looking at a cellphone', 'confidence': 0.7575129866600037, 'boundingBox': {'x': 977, 'y': 30, 'w': 922, 'h': 1019}}, {'text': 'a woman with long hair', 'confidence': 0.7050184011459351, 'boundingBox': {'x': 707, 'y': 12, 'w': 392, 'h': 353}}, {'text': 'a woman with long hair', 'confidence': 0.68263840675354, 'boundingBox': {'x': 213, 'y': 8, 'w': 1465, 'h': 363}}, {'text': 'a white piece of paper', 'confidence': 0.788602888584137, 'boundingBox': {'x': 45, 'y': 480, 'w': 58, 'h': 59}}, {'text': "a close up of a person's eye", 'confidence': 0.8406167030334473, 'boundingBox': {'x': 1641, 'y': 193, 'w': 78, 'h': 54}}, {'text': 'a man wearing a hoodie', 'confidence': 0.740642249584198, 'boundingBox': {'x': 1469, 'y': 42, 'w': 424, 'h': 524}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 453, 'y': 1, 'w': 734, 'h': 1076}, 'confidence': 0.9616192579269409}, {'boundingBox': {'x': 1032, 'y': 52, 'w': 885, 'h': 1025}, 'confidence': 0.9072524309158325}]}}
