{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man standing next to a man', 'confidence': 0.725370466709137, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man with his hand on his chin', 'confidence': 0.8263039588928223, 'boundingBox': {'x': 919, 'y': 184, 'w': 984, 'h': 871}}, {'text': 'a man holding a bag of chips', 'confidence': 0.7736999988555908, 'boundingBox': {'x': 0, 'y': 0, 'w': 983, 'h': 1048}}, {'text': 'a red box with a yellow and blue text', 'confidence': 0.6456723213195801, 'boundingBox': {'x': 0, 'y': 630, 'w': 333, 'h': 245}}, {'text': 'a zipper on a black background', 'confidence': 0.6779904961585999, 'boundingBox': {'x': 704, 'y': 333, 'w': 56, 'h': 83}}, {'text': 'a close up of a logo', 'confidence': 0.7582297325134277, 'boundingBox': {'x': 1273, 'y': 484, 'w': 60, 'h': 71}}, {'text': 'a man taking a selfie', 'confidence': 0.8330669403076172, 'boundingBox': {'x': 1306, 'y': 197, 'w': 563, 'h': 635}}, {'text': 'a close up of a balloon', 'confidence': 0.7805379629135132, 'boundingBox': {'x': 1061, 'y': 1, 'w': 79, 'h': 97}}, {'text': 'a white object with black lines', 'confidence': 0.5786041617393494, 'boundingBox': {'x': 964, 'y': 2, 'w': 99, 'h': 215}}, {'text': 'a close up of a hand', 'confidence': 0.849280595779419, 'boundingBox': {'x': 1430, 'y': 798, 'w': 315, 'h': 272}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 0, 'y': 1, 'w': 985, 'h': 1076}, 'confidence': 0.9620233774185181}, {'boundingBox': {'x': 897, 'y': 206, 'w': 1020, 'h': 871}, 'confidence': 0.9581394791603088}, {'boundingBox': {'x': 930, 'y': 716, 'w': 100, 'h': 122}, 'confidence': 0.7911257147789001}, {'boundingBox': {'x': 783, 'y': 694, 'w': 170, 'h': 383}, 'confidence': 0.3337407112121582}, {'boundingBox': {'x': 803, 'y': 695, 'w': 153, 'h': 173}, 'confidence': 0.27671757340431213}, {'boundingBox': {'x': 1068, 'y': 758, 'w': 32, 'h': 43}, 'confidence': 0.005268217530101538}, {'boundingBox': {'x': 1873, 'y': 810, 'w': 28, 'h': 42}, 'confidence': 0.004153807181864977}, {'boundingBox': {'x': 891, 'y': 744, 'w': 73, 'h': 125}, 'confidence': 0.0038165797013789415}, {'boundingBox': {'x': 118, 'y': 843, 'w': 45, 'h': 39}, 'confidence': 0.002879169536754489}, {'boundingBox': {'x': 165, 'y': 831, 'w': 45, 'h': 48}, 'confidence': 0.001981935929507017}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man standing next to a boy smoking a cigarette', 'confidence': 0.7504355311393738, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man with his hand on his chin', 'confidence': 0.8569921255111694, 'boundingBox': {'x': 899, 'y': 207, 'w': 999, 'h': 845}}, {'text': 'a man in a grey hoodie', 'confidence': 0.7805204391479492, 'boundingBox': {'x': 0, 'y': 0, 'w': 821, 'h': 1050}}, {'text': 'a desk and chair in a classroom', 'confidence': 0.7503955364227295, 'boundingBox': {'x': 728, 'y': 858, 'w': 294, 'h': 218}}, {'text': 'a close up of a logo', 'confidence': 0.7269509434700012, 'boundingBox': {'x': 1267, 'y': 479, 'w': 70, 'h': 91}}, {'text': 'a man standing next to a boy', 'confidence': 0.7979468703269958, 'boundingBox': {'x': 0, 'y': 0, 'w': 1898, 'h': 1044}}, {'text': 'a paper towel holder with a white paper towel holder', 'confidence': 0.5940145254135132, 'boundingBox': {'x': 950, 'y': 0, 'w': 108, 'h': 209}}, {'text': 'a blurry image of a white object', 'confidence': 0.7606930136680603, 'boundingBox': {'x': 537, 'y': 334, 'w': 63, 'h': 85}}, {'text': 'a close up of a balloon', 'confidence': 0.8073908686637878, 'boundingBox': {'x': 1060, 'y': 1, 'w': 80, 'h': 97}}, {'text': "a blurry image of a man's face", 'confidence': 0.8358001708984375, 'boundingBox': {'x': 904, 'y': 720, 'w': 94, 'h': 108}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 4, 'y': 1, 'w': 841, 'h': 1076}, 'confidence': 0.9640184044837952}, {'boundingBox': {'x': 901, 'y': 229, 'w': 1016, 'h': 847}, 'confidence': 0.953945517539978}, {'boundingBox': {'x': 692, 'y': 692, 'w': 265, 'h': 384}, 'confidence': 0.8985067009925842}, {'boundingBox': {'x': 908, 'y': 728, 'w': 118, 'h': 112}, 'confidence': 0.5749611854553223}, {'boundingBox': {'x': 766, 'y': 692, 'w': 193, 'h': 192}, 'confidence': 0.02823810465633869}, {'boundingBox': {'x': 1870, 'y': 808, 'w': 31, 'h': 50}, 'confidence': 0.003792405826970935}, {'boundingBox': {'x': 1070, 'y': 761, 'w': 24, 'h': 38}, 'confidence': 0.00194116763304919}, {'boundingBox': {'x': 1067, 'y': 746, 'w': 47, 'h': 47}, 'confidence': 0.0016570320585742593}, {'boundingBox': {'x': 892, 'y': 721, 'w': 126, 'h': 336}, 'confidence': 0.0013644821010529995}, {'boundingBox': {'x': 1074, 'y': 740, 'w': 75, 'h': 44}, 'confidence': 0.001029323902912438}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man standing next to a man in a room with other people', 'confidence': 0.6881317496299744, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man with his hand on his chin', 'confidence': 0.8524079918861389, 'boundingBox': {'x': 917, 'y': 203, 'w': 984, 'h': 851}}, {'text': 'a man in a grey hoodie', 'confidence': 0.7782379984855652, 'boundingBox': {'x': 0, 'y': 0, 'w': 802, 'h': 1051}}, {'text': 'a desk and chair in a classroom', 'confidence': 0.7174046039581299, 'boundingBox': {'x': 721, 'y': 858, 'w': 294, 'h': 216}}, {'text': 'a zipper with a white rectangular object', 'confidence': 0.6390472054481506, 'boundingBox': {'x': 513, 'y': 348, 'w': 55, 'h': 79}}, {'text': 'a man standing next to a man in a room with other people', 'confidence': 0.6879511475563049, 'boundingBox': {'x': 0, 'y': 0, 'w': 1901, 'h': 1043}}, {'text': "a blurry image of a man's face", 'confidence': 0.8631940484046936, 'boundingBox': {'x': 901, 'y': 734, 'w': 60, 'h': 85}}, {'text': 'a close up of a white object', 'confidence': 0.6255918145179749, 'boundingBox': {'x': 950, 'y': 0, 'w': 107, 'h': 209}}, {'text': 'a close up of a button', 'confidence': 0.7243623733520508, 'boundingBox': {'x': 1267, 'y': 482, 'w': 59, 'h': 80}}, {'text': 'a green balloon on a white background', 'confidence': 0.6644984483718872, 'boundingBox': {'x': 1061, 'y': 1, 'w': 79, 'h': 97}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 1, 'y': 1, 'w': 823, 'h': 1076}, 'confidence': 0.9643445014953613}, {'boundingBox': {'x': 901, 'y': 229, 'w': 1016, 'h': 848}, 'confidence': 0.9510539174079895}, {'boundingBox': {'x': 692, 'y': 693, 'w': 266, 'h': 384}, 'confidence': 0.8821793794631958}, {'boundingBox': {'x': 936, 'y': 717, 'w': 95, 'h': 119}, 'confidence': 0.6814649701118469}, {'boundingBox': {'x': 901, 'y': 737, 'w': 98, 'h': 120}, 'confidence': 0.050076987594366074}, {'boundingBox': {'x': 760, 'y': 692, 'w': 197, 'h': 208}, 'confidence': 0.02602807618677616}, {'boundingBox': {'x': 729, 'y': 771, 'w': 59, 'h': 93}, 'confidence': 0.01025827694684267}, {'boundingBox': {'x': 669, 'y': 771, 'w': 120, 'h': 306}, 'confidence': 0.007690920494496822}, {'boundingBox': {'x': 1871, 'y': 809, 'w': 31, 'h': 44}, 'confidence': 0.005126877222210169}, {'boundingBox': {'x': 1067, 'y': 746, 'w': 55, 'h': 47}, 'confidence': 0.0031820067670196295}, {'boundingBox': {'x': 1068, 'y': 760, 'w': 26, 'h': 36}, 'confidence': 0.0026330826804041862}, {'boundingBox': {'x': 893, 'y': 728, 'w': 114, 'h': 321}, 'confidence': 0.0014950609765946865}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man standing next to another man', 'confidence': 0.7637256979942322, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man taking a selfie', 'confidence': 0.9060636162757874, 'boundingBox': {'x': 870, 'y': 129, 'w': 1028, 'h': 928}}, {'text': 'a man in a grey jacket', 'confidence': 0.7405217885971069, 'boundingBox': {'x': 0, 'y': 0, 'w': 795, 'h': 1048}}, {'text': 'a person wearing a lanyard', 'confidence': 0.8805906176567078, 'boundingBox': {'x': 1231, 'y': 694, 'w': 293, 'h': 373}}, {'text': 'a close up of a man', 'confidence': 0.8342031836509705, 'boundingBox': {'x': 1159, 'y': 144, 'w': 509, 'h': 589}}, {'text': 'a man standing next to another man', 'confidence': 0.7735071182250977, 'boundingBox': {'x': 0, 'y': 0, 'w': 1900, 'h': 1043}}, {'text': 'a white desk with a chair and a person in the background', 'confidence': 0.6078519821166992, 'boundingBox': {'x': 723, 'y': 858, 'w': 251, 'h': 217}}, {'text': 'a white tube with a black handle', 'confidence': 0.5739210844039917, 'boundingBox': {'x': 951, 'y': 0, 'w': 106, 'h': 209}}, {'text': 'a person wearing a black hoodie', 'confidence': 0.8349335193634033, 'boundingBox': {'x': 759, 'y': 687, 'w': 190, 'h': 198}}, {'text': "a blurry image of a man's face", 'confidence': 0.8327468037605286, 'boundingBox': {'x': 899, 'y': 734, 'w': 57, 'h': 78}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 1, 'y': 1, 'w': 821, 'h': 1076}, 'confidence': 0.9658592343330383}, {'boundingBox': {'x': 878, 'y': 153, 'w': 1039, 'h': 924}, 'confidence': 0.9620932936668396}, {'boundingBox': {'x': 735, 'y': 692, 'w': 221, 'h': 385}, 'confidence': 0.7157416939735413}, {'boundingBox': {'x': 934, 'y': 716, 'w': 77, 'h': 114}, 'confidence': 0.47045937180519104}, {'boundingBox': {'x': 898, 'y': 734, 'w': 95, 'h': 119}, 'confidence': 0.0324493907392025}, {'boundingBox': {'x': 722, 'y': 769, 'w': 68, 'h': 96}, 'confidence': 0.008271832950413227}, {'boundingBox': {'x': 670, 'y': 766, 'w': 120, 'h': 311}, 'confidence': 0.004583577159792185}, {'boundingBox': {'x': 771, 'y': 687, 'w': 186, 'h': 186}, 'confidence': 0.001913056243211031}, {'boundingBox': {'x': 480, 'y': 684, 'w': 562, 'h': 393}, 'confidence': 0.0011087157763540745}]}}
