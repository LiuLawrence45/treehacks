{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle and a hand holding a phone', 'confidence': 0.7437365651130676, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8819364309310913, 'boundingBox': {'x': 370, 'y': 0, 'w': 675, 'h': 1048}}, {'text': 'a person holding a bottle', 'confidence': 0.7214935421943665, 'boundingBox': {'x': 855, 'y': 331, 'w': 135, 'h': 332}}, {'text': 'a man in a black hoodie looking at a cellphone', 'confidence': 0.8117559552192688, 'boundingBox': {'x': 1167, 'y': 0, 'w': 733, 'h': 1055}}, {'text': 'a woman wearing glasses and a black coat', 'confidence': 0.7243623733520508, 'boundingBox': {'x': 59, 'y': 896, 'w': 234, 'h': 178}}, {'text': 'a blurry image of a person wearing glasses', 'confidence': 0.8452250957489014, 'boundingBox': {'x': 131, 'y': 935, 'w': 95, 'h': 56}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8359965085983276, 'boundingBox': {'x': 0, 'y': 0, 'w': 1891, 'h': 1047}}, {'text': 'a close up of a tie', 'confidence': 0.7292851805686951, 'boundingBox': {'x': 1725, 'y': 525, 'w': 73, 'h': 384}}, {'text': 'a white piece of paper', 'confidence': 0.7647352814674377, 'boundingBox': {'x': 45, 'y': 481, 'w': 58, 'h': 59}}, {'text': 'a woman with long hair and a bottle of water', 'confidence': 0.7506454586982727, 'boundingBox': {'x': 175, 'y': 6, 'w': 1536, 'h': 388}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 391, 'y': 1, 'w': 676, 'h': 1076}, 'confidence': 0.9564136266708374}, {'boundingBox': {'x': 1190, 'y': 1, 'w': 727, 'h': 1075}, 'confidence': 0.9514227509498596}, {'boundingBox': {'x': 59, 'y': 905, 'w': 241, 'h': 172}, 'confidence': 0.8710594177246094}, {'boundingBox': {'x': 1253, 'y': 511, 'w': 91, 'h': 159}, 'confidence': 0.04140875115990639}, {'boundingBox': {'x': 0, 'y': 735, 'w': 501, 'h': 342}, 'confidence': 0.0011433796025812626}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle', 'confidence': 0.8555780053138733, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a hand holding a bottle of water', 'confidence': 0.8001964092254639, 'boundingBox': {'x': 860, 'y': 335, 'w': 125, 'h': 340}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8767821192741394, 'boundingBox': {'x': 385, 'y': 0, 'w': 710, 'h': 1047}}, {'text': 'a man in a black hoodie holding a phone', 'confidence': 0.7780929803848267, 'boundingBox': {'x': 1169, 'y': 0, 'w': 729, 'h': 1049}}, {'text': 'a woman holding a water bottle', 'confidence': 0.872414231300354, 'boundingBox': {'x': 0, 'y': 0, 'w': 1889, 'h': 1045}}, {'text': "blur a blurry image of a person's face", 'confidence': 0.82444167137146, 'boundingBox': {'x': 1157, 'y': 711, 'w': 291, 'h': 144}}, {'text': 'a white paper on a table', 'confidence': 0.6981391310691833, 'boundingBox': {'x': 44, 'y': 480, 'w': 58, 'h': 59}}, {'text': 'a pink book with black text', 'confidence': 0.6846737861633301, 'boundingBox': {'x': 401, 'y': 629, 'w': 96, 'h': 135}}, {'text': 'a woman smiling at camera', 'confidence': 0.7285144329071045, 'boundingBox': {'x': 149, 'y': 4, 'w': 1552, 'h': 412}}, {'text': 'a woman smiling for the camera', 'confidence': 0.7122112512588501, 'boundingBox': {'x': 682, 'y': 5, 'w': 346, 'h': 323}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 408, 'y': 0, 'w': 704, 'h': 1077}, 'confidence': 0.9579492211341858}, {'boundingBox': {'x': 1199, 'y': 1, 'w': 718, 'h': 1076}, 'confidence': 0.93610680103302}, {'boundingBox': {'x': 1252, 'y': 511, 'w': 94, 'h': 254}, 'confidence': 0.6023951768875122}, {'boundingBox': {'x': 0, 'y': 180, 'w': 105, 'h': 897}, 'confidence': 0.008021516725420952}, {'boundingBox': {'x': 0, 'y': 684, 'w': 91, 'h': 393}, 'confidence': 0.005527392495423555}, {'boundingBox': {'x': 1253, 'y': 510, 'w': 91, 'h': 100}, 'confidence': 0.0029199947603046894}, {'boundingBox': {'x': 1095, 'y': 575, 'w': 20, 'h': 25}, 'confidence': 0.001779415993951261}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle', 'confidence': 0.8646318316459656, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a hand holding a bottle of water', 'confidence': 0.8090869784355164, 'boundingBox': {'x': 865, 'y': 338, 'w': 127, 'h': 339}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8808713555335999, 'boundingBox': {'x': 405, 'y': 0, 'w': 703, 'h': 1049}}, {'text': 'a person in a hoodie', 'confidence': 0.7508570551872253, 'boundingBox': {'x': 1498, 'y': 0, 'w': 398, 'h': 1049}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8772556185722351, 'boundingBox': {'x': 0, 'y': 0, 'w': 1896, 'h': 1045}}, {'text': 'a close up of a tag', 'confidence': 0.7666824460029602, 'boundingBox': {'x': 1776, 'y': 481, 'w': 108, 'h': 584}}, {'text': "a close up of a man's face", 'confidence': 0.8588581681251526, 'boundingBox': {'x': 1617, 'y': 5, 'w': 298, 'h': 417}}, {'text': 'a woman smiling for the camera', 'confidence': 0.7152600884437561, 'boundingBox': {'x': 681, 'y': 9, 'w': 364, 'h': 348}}, {'text': 'a woman smiling at camera', 'confidence': 0.7081350088119507, 'boundingBox': {'x': 143, 'y': 5, 'w': 1576, 'h': 410}}, {'text': 'a piece of paper on a table', 'confidence': 0.8212805390357971, 'boundingBox': {'x': 44, 'y': 480, 'w': 60, 'h': 59}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 428, 'y': 1, 'w': 708, 'h': 1076}, 'confidence': 0.9598293304443359}, {'boundingBox': {'x': 1521, 'y': 1, 'w': 396, 'h': 1076}, 'confidence': 0.9544612169265747}, {'boundingBox': {'x': 1252, 'y': 512, 'w': 94, 'h': 250}, 'confidence': 0.8137573599815369}, {'boundingBox': {'x': 1112, 'y': 730, 'w': 18, 'h': 28}, 'confidence': 0.0016173709882423282}, {'boundingBox': {'x': 1095, 'y': 572, 'w': 23, 'h': 30}, 'confidence': 0.0012035527033731341}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle', 'confidence': 0.8817870020866394, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a bottle of water', 'confidence': 0.8246312141418457, 'boundingBox': {'x': 866, 'y': 336, 'w': 125, 'h': 343}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8680276870727539, 'boundingBox': {'x': 397, 'y': 0, 'w': 715, 'h': 1049}}, {'text': 'a person wearing a hoodie', 'confidence': 0.797602653503418, 'boundingBox': {'x': 1487, 'y': 0, 'w': 410, 'h': 1048}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8713893890380859, 'boundingBox': {'x': 0, 'y': 0, 'w': 1899, 'h': 1045}}, {'text': 'a man wearing a black hat', 'confidence': 0.6833911538124084, 'boundingBox': {'x': 1574, 'y': 2, 'w': 338, 'h': 494}}, {'text': 'a woman with her eyes closed', 'confidence': 0.7658205032348633, 'boundingBox': {'x': 679, 'y': 6, 'w': 344, 'h': 304}}, {'text': 'a white piece of paper', 'confidence': 0.8240904211997986, 'boundingBox': {'x': 45, 'y': 480, 'w': 58, 'h': 59}}, {'text': 'a woman with her eyes closed', 'confidence': 0.7749095559120178, 'boundingBox': {'x': 159, 'y': 4, 'w': 1557, 'h': 394}}, {'text': 'a pink book with black text', 'confidence': 0.6935790777206421, 'boundingBox': {'x': 397, 'y': 633, 'w': 112, 'h': 129}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 419, 'y': 0, 'w': 722, 'h': 1076}, 'confidence': 0.9596812725067139}, {'boundingBox': {'x': 1505, 'y': 1, 'w': 411, 'h': 1076}, 'confidence': 0.9520018696784973}, {'boundingBox': {'x': 1252, 'y': 512, 'w': 94, 'h': 250}, 'confidence': 0.8634159564971924}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a woman holding a water bottle', 'confidence': 0.8899329900741577, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a person holding a bottle of water', 'confidence': 0.8041001558303833, 'boundingBox': {'x': 859, 'y': 335, 'w': 130, 'h': 338}}, {'text': 'a woman holding a water bottle', 'confidence': 0.8786789178848267, 'boundingBox': {'x': 397, 'y': 0, 'w': 717, 'h': 1049}}, {'text': 'a person wearing a black hoodie', 'confidence': 0.8067486882209778, 'boundingBox': {'x': 1524, 'y': 0, 'w': 382, 'h': 1061}}, {'text': 'a woman holding a water bottle', 'confidence': 0.9024742245674133, 'boundingBox': {'x': 0, 'y': 0, 'w': 1890, 'h': 1045}}, {'text': 'a woman looking up to the side', 'confidence': 0.6905006170272827, 'boundingBox': {'x': 154, 'y': 6, 'w': 1591, 'h': 396}}, {'text': 'a close up of a lanyard', 'confidence': 0.8136230111122131, 'boundingBox': {'x': 1761, 'y': 492, 'w': 109, 'h': 575}}, {'text': 'a stack of white paper', 'confidence': 0.8059967160224915, 'boundingBox': {'x': 45, 'y': 481, 'w': 57, 'h': 57}}, {'text': 'a woman holding a water bottle', 'confidence': 0.9021732211112976, 'boundingBox': {'x': 404, 'y': 8, 'w': 861, 'h': 592}}, {'text': 'a fan in a room', 'confidence': 0.7363061904907227, 'boundingBox': {'x': 1139, 'y': 582, 'w': 133, 'h': 176}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'peopleResult': {'values': [{'boundingBox': {'x': 420, 'y': 0, 'w': 724, 'h': 1076}, 'confidence': 0.9609492421150208}, {'boundingBox': {'x': 1532, 'y': 0, 'w': 385, 'h': 1076}, 'confidence': 0.9479053616523743}, {'boundingBox': {'x': 1252, 'y': 512, 'w': 94, 'h': 249}, 'confidence': 0.8006515502929688}, {'boundingBox': {'x': 896, 'y': 361, 'w': 45, 'h': 60}, 'confidence': 0.0029034416656941175}, {'boundingBox': {'x': 461, 'y': 587, 'w': 46, 'h': 55}, 'confidence': 0.0024718292988836765}, {'boundingBox': {'x': 1253, 'y': 511, 'w': 91, 'h': 94}, 'confidence': 0.0012088954681530595}]}}
