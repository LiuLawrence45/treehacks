{
    'modelVersion': '2023-10-01', 
    'denseCaptionsResult': {
        'values': [
            {'text': 'a man holding up his hand', 'confidence': 0.8475540280342102, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, 
            {'text': 'a man holding up his hand', 'confidence': 0.7995085120201111, 'boundingBox': {'x': 494, 'y': 257, 'w': 1141, 'h': 794}}, {'text': 'a person with a backpack', 'confidence': 0.7348138093948364, 'boundingBox': {'x': 257, 'y': 287, 'w': 573, 'h': 781}}, 
            {'text': 'a close up of a phone', 'confidence': 0.6930582523345947, 'boundingBox': {'x': 1218, 'y': 464, 'w': 154, 'h': 119}}, 
            {'text': 'a green exit sign with white text', 'confidence': 0.7100639939308167, 'boundingBox': {'x': 263, 'y': 374, 'w': 59, 'h': 61}}, 
            {'text': 'a blue and white backpack', 'confidence': 0.7642353177070618, 'boundingBox': {'x': 329, 'y': 296, 'w': 503, 'h': 435}}, 
            {'text': 'a close up of a logo', 'confidence': 0.7491824626922607, 'boundingBox': {'x': 1242, 'y': 481, 'w': 69, 'h': 69}}, 
            {'text': 'a close-up of a lanyard', 'confidence': 0.7811582088470459, 'boundingBox': {'x': 827, 'y': 676, 'w': 223, 'h': 390}}, 
            {'text': "a close up of a man's face", 'confidence': 0.8210793137550354, 'boundingBox': {'x': 772, 'y': 264, 'w': 336, 'h': 417}}, 
            {'text': 'a blurry image of a sign', 'confidence': 0.8436214327812195, 'boundingBox': {'x': 1797, 'y': 828, 'w': 56, 'h': 114}}]}, 'metadata': {'width': 1920, 'height': 1080}, 
        
    'objectsResult': {
        'values': [
            {'boundingBox': {'x': 5, 'y': 675, 'w': 165, 'h': 399}, 'tags': [{'name': 'person', 'confidence': 0.685}]}, 
            {'boundingBox': {'x': 263, 'y': 298, 'w': 578, 'h': 764}, 'tags': [{'name': 'person', 'confidence': 0.536}]}, 
            {'boundingBox': {'x': 524, 'y': 273, 'w': 954, 'h': 807}, 'tags': [{'name': 'person', 'confidence': 0.8}]}]}, 
            
    'peopleResult': {
        'values': [{'boundingBox': {'x': 516, 'y': 273, 'w': 1133, 'h': 804}, 'confidence': 0.9675809741020203}, 
            {'boundingBox': {'x': 0, 'y': 667, 'w': 148, 'h': 387}, 'confidence': 0.7820984125137329}, 
            {'boundingBox': {'x': 86, 'y': 626, 'w': 263, 'h': 451}, 'confidence': 0.32697638869285583}, 
            {'boundingBox': {'x': 1857, 'y': 615, 'w': 59, 'h': 251}, 'confidence': 0.22887009382247925}, 
            {'boundingBox': {'x': 1849, 'y': 658, 'w': 68, 'h': 419}, 'confidence': 0.013959272764623165}, 
            {'boundingBox': {'x': 264, 'y': 292, 'w': 579, 'h': 785}, 'confidence': 0.010506901890039444}, 
            {'boundingBox': {'x': 1888, 'y': 571, 'w': 29, 'h': 228}, 'confidence': 0.0034786472097039223}, 
            {'boundingBox': {'x': 146, 'y': 626, 'w': 197, 'h': 239}, 'confidence': 0.003019832307472825}, 
            {'boundingBox': {'x': 241, 'y': 631, 'w': 98, 'h': 124}, 'confidence': 0.0023689502850174904}, 
            {'boundingBox': {'x': 0, 'y': 758, 'w': 58, 'h': 319}, 'confidence': 0.001018931739963591}]}}





{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man wearing earphones and holding up his hand', 'confidence': 0.7165002822875977, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man wearing earphones and holding his hand up', 'confidence': 0.7493917346000671, 'boundingBox': {'x': 499, 'y': 253, 'w': 1083, 'h': 800}}, {'text': 'a person wearing a backpack', 'confidence': 0.7763842344284058, 'boundingBox': {'x': 271, 'y': 281, 'w': 559, 'h': 787}}, {'text': 'a green exit sign with white text', 'confidence': 0.7199784517288208, 'boundingBox': {'x': 263, 'y': 374, 'w': 58, 'h': 60}}, {'text': "a close up of a man's face", 'confidence': 0.8169628381729126, 'boundingBox': {'x': 774, 'y': 261, 'w': 341, 'h': 417}}, {'text': 'a man wearing sunglasses', 'confidence': 0.6459888815879822, 'boundingBox': {'x': 1649, 'y': 642, 'w': 126, 'h': 205}}, {'text': 'a close-up of a lanyard', 'confidence': 0.8207240700721741, 'boundingBox': {'x': 824, 'y': 677, 'w': 228, 'h': 389}}, {'text': 'a blue backpack with white zippers', 'confidence': 0.7270978689193726, 'boundingBox': {'x': 336, 'y': 290, 'w': 487, 'h': 439}}, {'text': 'a green balloons in the ceiling', 'confidence': 0.6576086282730103, 'boundingBox': {'x': 24, 'y': 2, 'w': 312, 'h': 235}}, {'text': 'a blurry image of a green object', 'confidence': 0.679745614528656, 'boundingBox': {'x': 1136, 'y': 29, 'w': 81, 'h': 108}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'objectsResult': {'values': [{'boundingBox': {'x': 1379, 'y': 676, 'w': 153, 'h': 184}, 'tags': [{'name': 'person', 'confidence': 0.565}]}, {'boundingBox': {'x': 1652, 'y': 647, 'w': 130, 'h': 191}, 'tags': [{'name': 'person', 'confidence': 0.735}]}, {'boundingBox': {'x': 7, 'y': 667, 'w': 166, 'h': 413}, 'tags': [{'name': 'person', 'confidence': 0.689}]}, {'boundingBox': {'x': 268, 'y': 299, 'w': 578, 'h': 758}, 'tags': [{'name': 'person', 'confidence': 0.532}]}, {'boundingBox': {'x': 536, 'y': 268, 'w': 946, 'h': 812}, 'tags': [{'name': 'person', 'confidence': 0.854}]}]}, 'peopleResult': {'values': [{'boundingBox': {'x': 515, 'y': 270, 'w': 1107, 'h': 807}, 'confidence': 0.9620841145515442}, {'boundingBox': {'x': 0, 'y': 663, 'w': 147, 'h': 413}, 'confidence': 0.8296410441398621}, {'boundingBox': {'x': 1659, 'y': 650, 'w': 121, 'h': 206}, 'confidence': 0.8094524145126343}, {'boundingBox': {'x': 1389, 'y': 653, 'w': 162, 'h': 198}, 'confidence': 0.5528877973556519}, {'boundingBox': {'x': 92, 'y': 638, 'w': 248, 'h': 439}, 'confidence': 0.44966500997543335}, {'boundingBox': {'x': 270, 'y': 305, 'w': 454, 'h': 772}, 'confidence': 0.006295186001807451}, {'boundingBox': {'x': 1875, 'y': 686, 'w': 42, 'h': 391}, 'confidence': 0.005576699506491423}, {'boundingBox': {'x': 1388, 'y': 655, 'w': 252, 'h': 325}, 'confidence': 0.0035480603110045195}, {'boundingBox': {'x': 0, 'y': 756, 'w': 56, 'h': 321}, 'confidence': 0.0014551852364093065}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man wearing earphones and looking at the camera', 'confidence': 0.6946271657943726, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man wearing earbuds and a hoodie', 'confidence': 0.7131316661834717, 'boundingBox': {'x': 496, 'y': 250, 'w': 905, 'h': 807}}, {'text': 'a person carrying a backpack', 'confidence': 0.7668516635894775, 'boundingBox': {'x': 272, 'y': 280, 'w': 554, 'h': 791}}, {'text': 'a green sign with white text', 'confidence': 0.6900551915168762, 'boundingBox': {'x': 264, 'y': 374, 'w': 58, 'h': 61}}, {'text': 'a close up of a phone', 'confidence': 0.7190655469894409, 'boundingBox': {'x': 1218, 'y': 465, 'w': 153, 'h': 117}}, {'text': 'a person wearing headphones', 'confidence': 0.8665351271629333, 'boundingBox': {'x': 512, 'y': 651, 'w': 895, 'h': 413}}, {'text': 'a man wearing a hoodie', 'confidence': 0.8527487516403198, 'boundingBox': {'x': 1280, 'y': 648, 'w': 260, 'h': 245}}, {'text': 'a close up of a button', 'confidence': 0.7572888135910034, 'boundingBox': {'x': 1246, 'y': 483, 'w': 61, 'h': 56}}, {'text': 'blur a blurry picture of a phone', 'confidence': 0.7082773447036743, 'boundingBox': {'x': 1797, 'y': 828, 'w': 55, 'h': 116}}, {'text': 'a blue and white backpack', 'confidence': 0.7663945555686951, 'boundingBox': {'x': 332, 'y': 289, 'w': 488, 'h': 432}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'objectsResult': {'values': [{'boundingBox': {'x': 1444, 'y': 655, 'w': 132, 'h': 178}, 'tags': [{'name': 'person', 'confidence': 0.629}]}, {'boundingBox': {'x': 6, 'y': 671, 'w': 161, 'h': 409}, 'tags': [{'name': 'person', 'confidence': 0.702}]}, {'boundingBox': {'x': 1298, 'y': 661, 'w': 265, 'h': 312}, 'tags': [{'name': 'person', 'confidence': 0.715}]}, {'boundingBox': {'x': 273, 'y': 301, 'w': 564, 'h': 757}, 'tags': [{'name': 'person', 'confidence': 0.524}]}, {'boundingBox': {'x': 540, 'y': 274, 'w': 895, 'h': 806}, 'tags': [{'name': 'person', 'confidence': 0.841}]}]}, 'peopleResult': {'values': [{'boundingBox': {'x': 514, 'y': 270, 'w': 923, 'h': 807}, 'confidence': 0.9572247266769409}, {'boundingBox': {'x': 1275, 'y': 650, 'w': 271, 'h': 254}, 'confidence': 0.8854389786720276}, {'boundingBox': {'x': 0, 'y': 663, 'w': 145, 'h': 410}, 'confidence': 0.795498251914978}, {'boundingBox': {'x': 1455, 'y': 655, 'w': 101, 'h': 176}, 'confidence': 0.784665048122406}, {'boundingBox': {'x': 88, 'y': 632, 'w': 257, 'h': 445}, 'confidence': 0.4771813154220581}, {'boundingBox': {'x': 272, 'y': 288, 'w': 571, 'h': 788}, 'confidence': 0.00810912810266018}, {'boundingBox': {'x': 1874, 'y': 682, 'w': 43, 'h': 395}, 'confidence': 0.001995009370148182}, {'boundingBox': {'x': 0, 'y': 763, 'w': 64, 'h': 314}, 'confidence': 0.0018273191526532173}, {'boundingBox': {'x': 1216, 'y': 548, 'w': 499, 'h': 456}, 'confidence': 0.001606356236152351}, {'boundingBox': {'x': 248, 'y': 640, 'w': 92, 'h': 120}, 'confidence': 0.0016055835876613855}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man taking a selfie', 'confidence': 0.8569188117980957, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man wearing earbuds and smiling', 'confidence': 0.6855589151382446, 'boundingBox': {'x': 485, 'y': 228, 'w': 1037, 'h': 826}}, {'text': 'a person with a backpack', 'confidence': 0.7211560010910034, 'boundingBox': {'x': 264, 'y': 281, 'w': 539, 'h': 787}}, {'text': 'a green exit sign on a ceiling', 'confidence': 0.6721873879432678, 'boundingBox': {'x': 263, 'y': 374, 'w': 59, 'h': 60}}, {'text': 'a close up of a phone', 'confidence': 0.7217904925346375, 'boundingBox': {'x': 1218, 'y': 464, 'w': 151, 'h': 118}}, {'text': 'a man taking a selfie', 'confidence': 0.8138184547424316, 'boundingBox': {'x': 744, 'y': 236, 'w': 360, 'h': 436}}, {'text': 'a man wearing a hoodie', 'confidence': 0.8605450391769409, 'boundingBox': {'x': 1317, 'y': 647, 'w': 226, 'h': 245}}, {'text': 'a close up of a button', 'confidence': 0.8004128932952881, 'boundingBox': {'x': 1240, 'y': 481, 'w': 79, 'h': 71}}, {'text': 'a close-up of a white earbuds', 'confidence': 0.7455876469612122, 'boundingBox': {'x': 831, 'y': 709, 'w': 172, 'h': 357}}, {'text': 'a blurry image of a round object', 'confidence': 0.761523425579071, 'boundingBox': {'x': 1136, 'y': 29, 'w': 81, 'h': 107}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'objectsResult': {'values': [{'boundingBox': {'x': 19, 'y': 0, 'w': 244, 'h': 242}, 'tags': [{'name': 'Toy', 'confidence': 0.502}]}, {'boundingBox': {'x': 1313, 'y': 674, 'w': 265, 'h': 240}, 'tags': [{'name': 'person', 'confidence': 0.718}]}, {'boundingBox': {'x': 2, 'y': 671, 'w': 180, 'h': 398}, 'tags': [{'name': 'person', 'confidence': 0.72}]}, {'boundingBox': {'x': 528, 'y': 242, 'w': 979, 'h': 838}, 'tags': [{'name': 'person', 'confidence': 0.874}]}]}, 'peopleResult': {'values': [{'boundingBox': {'x': 498, 'y': 244, 'w': 1057, 'h': 833}, 'confidence': 0.9552416205406189}, {'boundingBox': {'x': 1315, 'y': 651, 'w': 242, 'h': 253}, 'confidence': 0.8628836274147034}, {'boundingBox': {'x': 0, 'y': 662, 'w': 153, 'h': 413}, 'confidence': 0.8191807866096497}, {'boundingBox': {'x': 85, 'y': 647, 'w': 253, 'h': 430}, 'confidence': 0.32383352518081665}, {'boundingBox': {'x': 268, 'y': 286, 'w': 455, 'h': 791}, 'confidence': 0.007706108968704939}, {'boundingBox': {'x': 145, 'y': 679, 'w': 183, 'h': 184}, 'confidence': 0.0031047218944877386}, {'boundingBox': {'x': 1252, 'y': 633, 'w': 478, 'h': 416}, 'confidence': 0.0018655142048373818}, {'boundingBox': {'x': 0, 'y': 759, 'w': 54, 'h': 318}, 'confidence': 0.0017614690586924553}]}}
{'modelVersion': '2023-10-01', 'denseCaptionsResult': {'values': [{'text': 'a man taking a selfie', 'confidence': 0.8550503849983215, 'boundingBox': {'x': 0, 'y': 0, 'w': 1920, 'h': 1080}}, {'text': 'a man wearing earphones and taking a selfie', 'confidence': 0.7382335662841797, 'boundingBox': {'x': 447, 'y': 160, 'w': 1037, 'h': 893}}, {'text': 'a person carrying a blue and white bag', 'confidence': 0.7275918126106262, 'boundingBox': {'x': 260, 'y': 190, 'w': 527, 'h': 856}}, {'text': 'a close up of a phone', 'confidence': 0.7832935452461243, 'boundingBox': {'x': 1217, 'y': 463, 'w': 153, 'h': 118}}, {'text': 'a green sign with white letters', 'confidence': 0.712041974067688, 'boundingBox': {'x': 262, 'y': 372, 'w': 61, 'h': 61}}, {'text': 'a man taking a selfie', 'confidence': 0.8159729838371277, 'boundingBox': {'x': 732, 'y': 173, 'w': 422, 'h': 516}}, {'text': 'a close up of a phone', 'confidence': 0.7917636036872864, 'boundingBox': {'x': 1234, 'y': 478, 'w': 102, 'h': 82}}, {'text': 'a man wearing a hoodie', 'confidence': 0.86106938123703, 'boundingBox': {'x': 1334, 'y': 646, 'w': 207, 'h': 246}}, {'text': 'a close up of a bottle', 'confidence': 0.8087490200996399, 'boundingBox': {'x': 1697, 'y': 821, 'w': 71, 'h': 143}}, {'text': 'a person wearing a black shirt with white headphones around neck', 'confidence': 0.7261413335800171, 'boundingBox': {'x': 786, 'y': 637, 'w': 333, 'h': 435}}]}, 'metadata': {'width': 1920, 'height': 1080}, 'objectsResult': {'values': [{'boundingBox': {'x': 214, 'y': 595, 'w': 125, 'h': 170}, 'tags': [{'name': 'person', 'confidence': 0.579}]}, {'boundingBox': {'x': 1322, 'y': 675, 'w': 255, 'h': 237}, 'tags': [{'name': 'person', 'confidence': 0.723}]}, {'boundingBox': {'x': 6, 'y': 669, 'w': 155, 'h': 408}, 'tags': [{'name': 'person', 'confidence': 0.687}]}, {'boundingBox': {'x': 247, 'y': 203, 'w': 543, 'h': 861}, 'tags': [{'name': 'person', 'confidence': 0.759}]}, {'boundingBox': {'x': 490, 'y': 223, 'w': 1004, 'h': 846}, 'tags': [{'name': 'person', 'confidence': 0.821}]}]}, 'peopleResult': {'values': [{'boundingBox': {'x': 458, 'y': 179, 'w': 1049, 'h': 898}, 'confidence': 0.9553738236427307}, {'boundingBox': {'x': 1334, 'y': 650, 'w': 222, 'h': 253}, 'confidence': 0.8477340936660767}, {'boundingBox': {'x': 0, 'y': 665, 'w': 145, 'h': 410}, 'confidence': 0.7882820963859558}, {'boundingBox': {'x': 211, 'y': 573, 'w': 134, 'h': 204}, 'confidence': 0.7857063412666321}, {'boundingBox': {'x': 273, 'y': 207, 'w': 539, 'h': 870}, 'confidence': 0.6622321605682373}, {'boundingBox': {'x': 48, 'y': 660, 'w': 275, 'h': 417}, 'confidence': 0.02920999377965927}, {'boundingBox': {'x': 1235, 'y': 631, 'w': 485, 'h': 413}, 'confidence': 0.0015589062822982669}, {'boundingBox': {'x': 0, 'y': 750, 'w': 56, 'h': 327}, 'confidence': 0.0012155434815213084}]}}
